{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL0-SUYRm0zu"
      },
      "source": [
        "# Machine Learning Lab - Steel Industry\n",
        "## Part 4: Anomaly Detection with Deep Learning\n",
        "\n",
        "In this part, we will use convolutional neural networks (CNN) with PyTorch to detect anomalies in industrial images, using the MVTec AD dataset.\n",
        "\n",
        "### Objectives:\n",
        "- Understand the principles of anomaly detection with Deep Learning\n",
        "- Implement a CNN model with PyTorch\n",
        "- Evaluate and visualize the results\n",
        "\n",
        "### Methods covered:\n",
        "- Convolutional autoencoders with PyTorch\n",
        "- Transfer Learning\n",
        "- Anomaly detection metrics\n",
        "\n",
        "⚠️ **Important**: Before starting, activate the GPU:\n",
        "1. Menu \"Runtime\" > \"Change runtime type\"\n",
        "2. Select \"T4 GPU\" in the \"Hardware accelerator\" dropdown\n",
        "3. Click \"Save\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hSIpCzwNm7oB",
        "outputId": "179d4b42-4d47-4e49-c647-22fb89f6f558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n",
            "GPU name: Tesla T4\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Import necessary packages\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "import torch.distributions as dist\n",
        "\n",
        "# GPU check\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Configuration\n",
        "sns.set_theme(style='whitegrid')\n",
        "%matplotlib inline\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiGWKlp9m93B"
      },
      "source": [
        "### 1. Loading and preparing the MVTec AD data (Bottle dataset)\n",
        "\n",
        "The MVTec AD dataset contains industrial images of different objects, with normal and abnormal examples.\n",
        "\n",
        "❓ Questions about the data:\n",
        "- Why use only \"normal\" images for training?\n",
        "- How does this reflect industrial reality?\n",
        "- What is the purpose of data augmentation in this context?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HORH9jwWm_rA",
        "outputId": "0876cd0f-767b-4919-c9be-5fd7f4d26d7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset structure:\n",
            "sed: -e expression #2, char 20: unknown option to `s'\n",
            "\n",
            "Number of images:\n",
            "Training (normal): 209\n",
            "Test (normal): 20\n",
            "Test (anomalies): 20\n"
          ]
        }
      ],
      "source": [
        "# Create directory for the dataset\n",
        "!mkdir -p mvtec_data\n",
        "\n",
        "# Download only the bottle dataset\n",
        "!wget -P mvtec_data https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420938113-1629952094/bottle.tar.xz\n",
        "!cd mvtec_data\n",
        "!tar -xf bottle.tar.xz\n",
        "\n",
        "# Check dataset structure\n",
        "print(\"\\nDataset structure:\")\n",
        "!ls -R mvtec_data/bottle | grep \":$\" | sed -e 's/:$//' -e 's/[^-][^\\\\/]*\\\\//  /g' -e 's/^/  /'\n",
        "\n",
        "# Create a custom Dataset\n",
        "class MVTecDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Downscale from 256x256 to 128x128\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(num_output_channels=3)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Downscale from 256x256 to 128x128\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(num_output_channels=3)\n",
        "])\n",
        "\n",
        "# Create datasets with new paths\n",
        "train_dataset = MVTecDataset('mvtec_data/bottle/train/good', transform=train_transform)\n",
        "test_normal_dataset = MVTecDataset('mvtec_data/bottle/test/good', transform=test_transform)\n",
        "# /!\\\\ Complete the '...' to create a test_anomaly_dataset sourced from mvtec_data/bottle/test/broken_large images /!\\\\\n",
        "test_anomaly_dataset = MVTecDataset(\"mvtec_data/bottle/test/broken_large\")\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # Batch size changed from 32 to 16\n",
        "test_normal_loader = DataLoader(test_normal_dataset, batch_size=16, shuffle=False)\n",
        "test_anomaly_loader = DataLoader(test_anomaly_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"\\nNumber of images:\")\n",
        "print(f\"Training (normal): {len(train_dataset)}\")\n",
        "print(f\"Test (normal): {len(test_normal_dataset)}\")\n",
        "print(f\"Test (anomalies): {len(test_anomaly_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh5uECbKnfs1"
      },
      "source": [
        "### 2. Creating the Autoencoder model with PyTorch\n",
        "\n",
        "❓ Questions about the architecture:\n",
        "- Why choose an encoder-decoder architecture?\n",
        "- What does the latent space represent in our industrial context?\n",
        "- How does the bottleneck force the learning of relevant features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NumzTqztngh3"
      },
      "outputs": [],
      "source": [
        "class ImprovedAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedAutoencoder, self).__init__()\n",
        "\n",
        "        # Reduced number of filters\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),  # 64 -> 32\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),  # 128 -> 64\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),  # 256 -> 128\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),  # 512 -> 256\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        # Decoder (update dimensions accordingly)\n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 3, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoding\n",
        "        e1 = self.enc1(x)\n",
        "        p1 = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc3(p2)\n",
        "        p3 = self.pool3(e3)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(p3)\n",
        "\n",
        "        # Decoding with skip connections\n",
        "        d3 = self.up3(b)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        return d1, b\n",
        "\n",
        "# Enhanced loss with structural component\n",
        "class EnhancedLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7, beta=0.3):\n",
        "        super(EnhancedLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.l1 = nn.L1Loss()\n",
        "\n",
        "    def forward(self, output, target, encoded_output, encoded_target):\n",
        "        # MSE for global reconstruction\n",
        "        mse_loss = self.mse(output, target)\n",
        "\n",
        "        # L1 for fine details\n",
        "        l1_loss = self.l1(output, target)\n",
        "\n",
        "        # MSE on the latent space\n",
        "        # /!\\\\ Complete the '...' to create a feature loss as an mse between encoded_output and encoded_target /!\\\\\n",
        "        feature_loss = self.mse(encoded_output, encoded_target)\n",
        "\n",
        "        # Combine losses\n",
        "        total_loss = self.alpha * (0.5 * mse_loss + 0.5 * l1_loss) + self.beta * feature_loss\n",
        "        return total_loss\n",
        "\n",
        "# Update datasets with new transformations\n",
        "train_dataset = MVTecDataset('mvtec_data/bottle/train/good', transform=train_transform)\n",
        "test_normal_dataset = MVTecDataset('mvtec_data/bottle/test/good', transform=test_transform)\n",
        "test_anomaly_dataset = MVTecDataset('mvtec_data/bottle/test/broken_large', transform=test_transform)\n",
        "\n",
        "# Create and move model to the appropriate device\n",
        "model = ImprovedAutoencoder().to(device)\n",
        "criterion = EnhancedLoss(alpha=0.7, beta=0.3)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kajC2Efd2BXh",
        "outputId": "fe54bc8c-13ae-44ab-b2e1-76f6d3bfefaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/100], Loss: 0.0134\n",
            "Epoch [10/100], Loss: 0.0049\n",
            "Epoch [15/100], Loss: 0.0040\n",
            "Epoch [20/100], Loss: 0.0037\n",
            "Epoch [25/100], Loss: 0.0043\n",
            "Epoch [30/100], Loss: 0.0028\n",
            "Epoch [35/100], Loss: 0.0031\n",
            "Epoch [40/100], Loss: 0.0026\n",
            "Epoch [45/100], Loss: 0.0030\n",
            "Epoch [50/100], Loss: 0.0028\n",
            "Epoch [55/100], Loss: 0.0027\n",
            "Epoch [60/100], Loss: 0.0024\n",
            "Epoch [65/100], Loss: 0.0022\n",
            "Early stopping at epoch 69\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Improved training function\n",
        "def train_improved_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with encoded features\n",
        "        reconstructed, encoded = model(batch)\n",
        "        with torch.no_grad():\n",
        "            _, target_encoded = model(batch)\n",
        "\n",
        "        # Compute combined loss\n",
        "        loss = criterion(reconstructed, batch, encoded, target_encoded.detach())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Explicit memory release\n",
        "        del reconstructed, encoded, target_encoded\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Training with early stopping\n",
        "n_epochs = 100\n",
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "patience_counter = 0\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    loss = train_improved_epoch(model, train_loader, criterion, optimizer)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(loss)\n",
        "\n",
        "    # Early stopping\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        patience_counter = 0\n",
        "        # Save the best model\n",
        "        torch.save(model.state_dict(), 'best_autoencoder.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f'Early stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss:.4f}')\n",
        "\n",
        "# Load the best model for evaluation\n",
        "model.load_state_dict(torch.load('best_autoencoder.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvxp8R1Tno7i"
      },
      "source": [
        "### 3. Evaluation and anomaly detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VfWeK1SdnpnA",
        "outputId": "972e4b3e-8899-4538-8627-8b8d26d357e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-08a4b20f57e5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Compute reconstruction errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnormal_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_reconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_normal_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0manomaly_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_reconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_anomaly_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Visualization of error distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-08a4b20f57e5>\u001b[0m in \u001b[0;36mcompute_reconstruction_error\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mreconstructed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Unpack tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 ]\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def compute_reconstruction_error(model, dataloader):\n",
        "    model.eval()\n",
        "    errors = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        reconstructed, encoded = model(batch)  # Unpack tuple\n",
        "        error = torch.mean((batch - reconstructed) ** 2, dim=(1,2,3))\n",
        "        errors.extend(error.cpu().numpy())\n",
        "\n",
        "    return np.array(errors)\n",
        "\n",
        "# Compute reconstruction errors\n",
        "normal_errors = compute_reconstruction_error(model, test_normal_loader)\n",
        "anomaly_errors = compute_reconstruction_error(model, test_anomaly_loader)\n",
        "\n",
        "# Visualization of error distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(normal_errors, bins=50, alpha=0.5, label='Normal')\n",
        "plt.hist(anomaly_errors, bins=50, alpha=0.5, label='Anomaly')\n",
        "plt.title('Distribution of reconstruction errors')\n",
        "plt.xlabel('MSE')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Compute and display ROC curve\n",
        "y_true = np.concatenate([np.zeros(len(normal_errors)), np.ones(len(anomaly_errors))])\n",
        "# /!\\\\ Complete the '...' to create y_scores as the concatenation of normal_errors and anomaly_errors /!\\\\\n",
        "y_scores = np.concatenate([normal_errors, anomaly_errors])\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq82Yf0tns55"
      },
      "source": [
        "### 4. Results visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQl2ZWupnuXI"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def plot_results(model, dataloader, n=5):\n",
        "    model.eval()\n",
        "\n",
        "    # Get a batch\n",
        "    batch = next(iter(dataloader))\n",
        "    batch = batch[:n].to(device)\n",
        "    reconstructed, _ = model(batch)\n",
        "\n",
        "    # Convert for display\n",
        "    batch = batch.cpu()\n",
        "    reconstructed = reconstructed.cpu()\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # Original\n",
        "        plt.subplot(2, n, i + 1)\n",
        "        img = batch[i].permute(1, 2, 0).numpy()\n",
        "        plt.imshow(img, cmap='gray')  # Use cmap='gray' for grayscale images\n",
        "        plt.title('Original')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Reconstruction\n",
        "        plt.subplot(2, n, i + n + 1)\n",
        "        img = reconstructed[i].permute(1, 2, 0).numpy()\n",
        "        plt.imshow(img, cmap='gray')  # Use cmap='gray' for grayscale images\n",
        "        # /!\\\\ Complete the '...' to add the title 'Reconstruction' to the plot /!\\\\\n",
        "        plt.title('Reconstruction')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display results\n",
        "print(\"Normal examples:\")\n",
        "plot_results(model, test_normal_loader)\n",
        "\n",
        "print(\"\\nExamples with anomalies:\")\n",
        "plot_results(model, test_anomaly_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhHoD474nxPH"
      },
      "source": [
        "❓ Questions about the classic autoencoder:\n",
        "\n",
        "- Why are the reconstructions almost identical to the original images?\n",
        "- How to explain the small difference between the reconstruction errors of normal and abnormal images?\n",
        "- Did the autoencoder really learn the \"normal\" features of the bottles?\n",
        "- Is this \"too good\" reconstruction desirable for anomaly detection?\n",
        "- What happens if the autoencoder simply learns to \"copy\" the input?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANSE54Hl8OYF"
      },
      "source": [
        "### 5. Improvement with a Variational Autoencoder (VAE)\n",
        "\n",
        "To improve anomaly detection, we will use a VAE which should:\n",
        "- Better regularize the latent space\n",
        "- Learn a more robust distribution of normal images\n",
        "- Better \"repair\" anomalies in the reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1GDxHuw8PN_"
      },
      "outputs": [],
      "source": [
        "vae_train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x)\n",
        "])\n",
        "\n",
        "# /!\\ Complete the '...' to transform the input image to 128x128 resolution during the transformation /!\\\n",
        "vae_test_transform = transforms.Compose([\n",
        "    ...,\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x)\n",
        "])\n",
        "\n",
        "# Create new datasets for the VAE\n",
        "vae_train_dataset = MVTecDataset('mvtec_data/bottle/train/good', transform=vae_train_transform)\n",
        "vae_test_normal_dataset = MVTecDataset('mvtec_data/bottle/test/good', transform=vae_test_transform)\n",
        "vae_test_anomaly_dataset = MVTecDataset('mvtec_data/bottle/test/broken_large', transform=vae_test_transform)\n",
        "\n",
        "# Create dataloaders for the VAE\n",
        "vae_train_loader = DataLoader(vae_train_dataset, batch_size=16, shuffle=True)\n",
        "vae_test_normal_loader = DataLoader(vae_test_normal_dataset, batch_size=16, shuffle=False)\n",
        "vae_test_anomaly_loader = DataLoader(vae_test_anomaly_dataset, batch_size=16, shuffle=False)\n",
        "# Definition of the VAE\n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=64):  # Reduced latent dimension\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder inspired by the autoencoder that worked well\n",
        "        self.encoder = nn.Sequential(\n",
        "            # First block\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Second block\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Third block\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # mu and logvar projections\n",
        "        self.fc_mu = nn.Linear(128 * 16 * 16, latent_dim)\n",
        "        self.fc_var = nn.Linear(128 * 16 * 16, latent_dim)\n",
        "\n",
        "        # Symmetric decoder\n",
        "        self.decoder_input = nn.Linear(latent_dim, 128 * 16 * 16)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # First block\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Second block\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Third block\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Final layer\n",
        "            nn.Conv2d(32, 3, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc_mu(x), self.fc_var(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = torch.exp(0.5 * logvar)\n",
        "            eps = torch.randn_like(std)\n",
        "            return mu + eps * std\n",
        "        return mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.decoder_input(z)\n",
        "        z = z.view(z.size(0), 128, 16, 16)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "# Loss function with a very low KL weight\n",
        "class VAELoss(nn.Module):\n",
        "    def __init__(self, kld_weight=0.0001):  # Very low KL weight\n",
        "        super().__init__()\n",
        "        self.kld_weight = kld_weight\n",
        "\n",
        "    def forward(self, recon_x, x, mu, logvar):\n",
        "        recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
        "        kld_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return recon_loss + self.kld_weight * kld_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiniRoFV8ZO2"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "vae_model = VariationalAutoencoder().to(device)\n",
        "vae_criterion = VAELoss()\n",
        "vae_optimizer = optim.Adam(vae_model.parameters(), lr=0.0001)\n",
        "\n",
        "# VAE training function\n",
        "def train_vae_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        recon_batch, mu, logvar = model(batch)\n",
        "        loss = criterion(recon_batch, batch, mu, logvar)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# VAE training\n",
        "print(\"Starting VAE training...\")\n",
        "n_epochs = 100\n",
        "best_loss = float('inf')\n",
        "vae_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    loss = train_vae_epoch(vae_model, vae_train_loader, vae_criterion, vae_optimizer)\n",
        "    vae_losses.append(loss)\n",
        "\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        torch.save(vae_model.state_dict(), 'best_vae.pth')\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO9QpMPz8cn3"
      },
      "outputs": [],
      "source": [
        "# Visualization of VAE results\n",
        "@torch.no_grad()\n",
        "def plot_vae_results(model, dataloader, n=5):\n",
        "    model.eval()\n",
        "    batch = next(iter(dataloader))\n",
        "    batch = batch[:n].to(device)\n",
        "    recon, _, _ = model(batch)\n",
        "\n",
        "    batch = batch.cpu()\n",
        "    recon = recon.cpu()\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # Original\n",
        "        plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(batch[i].permute(1, 2, 0), cmap='gray')\n",
        "        plt.title('Original')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Reconstruction\n",
        "        plt.subplot(2, n, i + n + 1)\n",
        "        plt.imshow(recon[i].permute(1, 2, 0), cmap='gray')\n",
        "        plt.title('Reconstruction VAE')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nVAE results on normal images:\")\n",
        "plot_vae_results(vae_model, vae_test_normal_loader)\n",
        "\n",
        "print(\"\\nVAE results on images with anomalies:\")\n",
        "# /!\\ Complete the '...' to display the input and reconstructed images (vae_test_anomaly_loader) via the variational auto-encoder /!\\\n",
        "plot_vae_results(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWWpivq39Hsj"
      },
      "source": [
        "❓ Questions about the advantages of the VAE:\n",
        "- Why are VAE reconstructions more \"blurry\"?\n",
        "- How is this \"blurriness\" actually an advantage for anomaly detection?\n",
        "- How does the VAE handle unusual features differently?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PINXpbz1DhDP"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_vae(model, normal_loader, anomaly_loader):\n",
        "    model.eval()\n",
        "\n",
        "    normal_errors = []\n",
        "    anomaly_errors = []\n",
        "\n",
        "    # For normal images\n",
        "    for batch in normal_loader:\n",
        "        batch = batch.to(device)\n",
        "        recon, mu, logvar = model(batch)\n",
        "        # Pixel-wise reconstruction error\n",
        "        recon_error = F.mse_loss(recon, batch, reduction='none')\n",
        "        # Mean over channels only (keeps spatial dimensions)\n",
        "        recon_error = recon_error.mean(dim=1)\n",
        "        # Local maximum to detect local anomalies\n",
        "        recon_error = F.max_pool2d(recon_error, kernel_size=3, stride=1, padding=1)\n",
        "        # Mean over the image\n",
        "        recon_error = recon_error.mean(dim=(1,2))\n",
        "\n",
        "        normal_errors.extend(recon_error.cpu().numpy())\n",
        "\n",
        "    # For images with anomalies\n",
        "    for batch in anomaly_loader:\n",
        "        batch = batch.to(device)\n",
        "        recon, mu, logvar = model(batch)\n",
        "        recon_error = F.mse_loss(recon, batch, reduction='none')\n",
        "        recon_error = recon_error.mean(dim=1)\n",
        "        recon_error = F.max_pool2d(recon_error, kernel_size=3, stride=1, padding=1)\n",
        "        recon_error = recon_error.mean(dim=(1,2))\n",
        "\n",
        "        anomaly_errors.extend(recon_error.cpu().numpy())\n",
        "\n",
        "    # Error normalization\n",
        "    all_errors = np.concatenate([normal_errors, anomaly_errors])\n",
        "    error_mean = np.mean(all_errors)\n",
        "    error_std = np.std(all_errors)\n",
        "    normal_errors = (normal_errors - error_mean) / error_std\n",
        "    anomaly_errors = (anomaly_errors - error_mean) / error_std\n",
        "\n",
        "    # Compute metrics\n",
        "    y_true = np.concatenate([np.zeros(len(normal_errors)), np.ones(len(anomaly_errors))])\n",
        "    y_scores = np.concatenate([normal_errors, anomaly_errors])\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    return {\n",
        "        'normal_errors': normal_errors,\n",
        "        'anomaly_errors': anomaly_errors,\n",
        "        'AUC': roc_auc,\n",
        "        'FPR': fpr,\n",
        "        'TPR': tpr\n",
        "    }\n",
        "\n",
        "# Improved results visualization\n",
        "metrics = evaluate_vae(vae_model, vae_test_normal_loader, vae_test_anomaly_loader)\n",
        "\n",
        "# ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(metrics['FPR'], metrics['TPR'], color='darkorange', lw=2,\n",
        "         label=f'ROC curve (AUC = {metrics[\\\"AUC\\\"]:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve of the VAE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Error distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(metrics['normal_errors'], bins=50, alpha=0.7, label='Normal', density=True)\n",
        "plt.hist(metrics['anomaly_errors'], bins=50, alpha=0.7, label='Anomaly', density=True)\n",
        "plt.title('Distribution of normalized reconstruction errors')\n",
        "plt.xlabel('Reconstruction error (normalized)')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "# /!\\ Complete the '...' to display the plot /!\\\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0kN16Cm_c30"
      },
      "source": [
        "### Analysis of Anomaly Reconstructions\n",
        "\n",
        "❓ In-depth questions:\n",
        "- How does the VAE \"force\" the learning of useful features?\n",
        "- Why is the normal distribution constraint in the latent space important?\n",
        "- How could anomaly detection be further improved?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyqYPZi4Bc7g"
      },
      "source": [
        "### Conclusion and perspectives\n",
        "❓ Final questions:\n",
        "- Which model should be chosen for a real industrial application?\n",
        "- How to adapt these models to other types of anomalies?\n",
        "- What further improvements could be made?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}